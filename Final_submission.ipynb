{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "f2d8e88f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "import cv2\n",
    "import random\n",
    "import numpy as np\n",
    "import math\n",
    "import pandas as pd\n",
    "import string\n",
    "import time\n",
    "import math"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "335dd5f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Key functions\n",
    "def load_stop_words(stop_word_file):\n",
    "        # The stop words list is taken from the following github page- https://github.com/Alir3z4/stop-words/blob/master/english.txt\n",
    "        stop_words = []\n",
    "        with open(stop_word_file, 'r', encoding='utf8') as f:\n",
    "            stop_words = f.readlines()\n",
    "            stop_words = [word.strip() for word in stop_words]\n",
    "        return stop_words\n",
    "\n",
    "def prepare_bag_of_words(train_data, stop_words, cutoff=1):\n",
    "    deceptive_words = []\n",
    "    truthful_words = []\n",
    "    deceptive_sentences = []\n",
    "    truthful_sentences = []\n",
    "\n",
    "    for sentence, label in zip(train_data['full_text'], train_data['Target']):\n",
    "        sentence = sentence.lower()\n",
    "        # The following statement to remove punctuations is referred from- https://www.pythonpool.com/remove-punctuation-python/\n",
    "        # Reference starts here\n",
    "        sentence = sentence.translate(str.maketrans('','', string.punctuation))\n",
    "        # Reference ends here\n",
    "        sentence = sentence.split()\n",
    "        sentence = [word for word in sentence if word not in stop_words]\n",
    "        #Truthful=1\n",
    "        #Deceptive=0\n",
    "        if label == 1:\n",
    "            truthful_words.extend(sentence)\n",
    "            truthful_sentences.append(sentence)\n",
    "        elif label == 0:\n",
    "            deceptive_words.extend(sentence)\n",
    "            deceptive_sentences.append(sentence)\n",
    "\n",
    "    truthful_keys = list(set(truthful_words))\n",
    "    deceptive_keys = list(set(deceptive_words))\n",
    "\n",
    "    bag_of_words_truthful = {word:0 for word in truthful_keys}    \n",
    "    for sentence in truthful_sentences:\n",
    "        for word in truthful_keys:\n",
    "            if word in sentence:\n",
    "                bag_of_words_truthful[word] += 1\n",
    "    \n",
    "    bag_of_words_deceptive = {word:0 for word in deceptive_keys}\n",
    "    for sentence in deceptive_sentences:\n",
    "        for word in deceptive_keys:\n",
    "            if word in sentence:\n",
    "                bag_of_words_deceptive[word] += 1\n",
    "\n",
    "    # Reduce bag of words based on cutoff\n",
    "    bag_of_words_truthful = {k:v for k,v in bag_of_words_truthful.items() if v > cutoff}\n",
    "    bag_of_words_deceptive = {k:v for k,v in bag_of_words_deceptive.items() if v > cutoff}\n",
    "\n",
    "    # Calculate probability of truthful and deceptive\n",
    "    p_of_truthful = len(truthful_sentences)/(len(truthful_sentences ) + len(deceptive_sentences))\n",
    "    p_of_deceptive = len(deceptive_sentences)/(len(truthful_sentences) + len(deceptive_sentences))\n",
    "\n",
    "    return len(truthful_sentences), len(deceptive_sentences), bag_of_words_deceptive, bag_of_words_truthful, p_of_truthful, p_of_deceptive\n",
    "\n",
    "def prepare_test_message(sentence, stop_words):\n",
    "    sentence = sentence.lower()\n",
    "    sentence = sentence.translate(str.maketrans('','', string.punctuation))\n",
    "    sentence = sentence.split()\n",
    "    sentence = [word for word in sentence if word not in stop_words]\n",
    "    return sentence  \n",
    "\n",
    "def classifier(train_data, test_data):\n",
    "    alpha = 1\n",
    "    stop_words = load_stop_words(\"stop_words.txt\")\n",
    "    predicted = []\n",
    "\n",
    "    no_of_truthful_msg, no_of_deceptive_msg, bag_of_words_deceptive, \\\n",
    "        bag_of_words_truthful, p_of_truthful, p_of_deceptive = prepare_bag_of_words(train_data, stop_words)\n",
    "\n",
    "    for sentence in test_data['full_text']:\n",
    "        sentence = prepare_test_message(sentence, stop_words) \n",
    "        p_of_word_given_truthful = 0\n",
    "        p_of_word_given_deceptive = 0\n",
    "        \n",
    "        for word in sentence:\n",
    "            p_of_word_given_truthful += math.log((bag_of_words_truthful.get(word, 0) + alpha)/(no_of_truthful_msg + alpha*len(bag_of_words_truthful)))\n",
    "            p_of_word_given_deceptive += math.log((bag_of_words_deceptive.get(word, 0) + alpha)/(no_of_deceptive_msg + alpha*len(bag_of_words_deceptive)))\n",
    "\n",
    "        # Applying log on probabilities\n",
    "        p_of_truthful_given_word = p_of_word_given_truthful + math.log(p_of_truthful)\n",
    "        p_of_deceptive_given_word = p_of_word_given_deceptive + math.log(p_of_deceptive)\n",
    "\n",
    "        # if p_of_truthful_given_word - p_of_deceptive_given_word > 0:\n",
    "        #     predicted.append(1)\n",
    "        #     # print(\"Truthful\")\n",
    "        # else:\n",
    "        #     # print(\"Deceptive\")\n",
    "        #     predicted.append(0)\n",
    "        \n",
    "        dummy_val_deceptive=np.exp(p_of_deceptive_given_word)\n",
    "        dummy_val_truthful=np.exp(p_of_truthful_given_word)\n",
    "        try:\n",
    "            modified_val_spam=dummy_val_deceptive/(dummy_val_deceptive+dummy_val_truthful)\n",
    "        except:\n",
    "            modified_val_spam=0\n",
    "        modified_val_truthful=1-modified_val_spam\n",
    "        predicted.append(modified_val_truthful)\n",
    "    return predicted"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "8c88bd61",
   "metadata": {},
   "outputs": [],
   "source": [
    "os.chdir(r\"C:\\Key files- GNA\\Indiana University\\Hackathon\\Data Science- March\")\n",
    "train_dataset=pd.read_csv(\"New_train_dataset.csv\")\n",
    "\n",
    "train_dataset_filtered=train_dataset.drop(['Additional.Comments.x','Additional.Comments.y','sample_name','create_date','Unnamed: 0', 'Unnamed: 0.1','ID', 'user','userID','Sample.ID.x','Sample.ID.y','In.English.x', 'In.English.y','User.x', 'User.y'],axis=1)\n",
    "\n",
    "#Cleaning\n",
    "df=train_dataset_filtered\n",
    "# merge two columns that are same just few values are in one column and rest in other\n",
    "df['Is.About.the.Holocaust.x'] = df['Is.About.the.Holocaust.x'].fillna(df['Is.About.The.Holocaust.x'])\n",
    "df['Is.About.the.Holocaust.y'] = df['Is.About.the.Holocaust.y'].fillna(df['Is.About.The.Holocaust.y'])\n",
    "# drop the unwanted columns \n",
    "df.drop(['Is.About.The.Holocaust.x','Is.About.The.Holocaust.y'],inplace=True,axis=1)\n",
    "\n",
    "# Average out to columns that have same meaning except are filled by different experts\n",
    "# Approach used: average out the values \n",
    "df['Still.Exists'] = df[['Still.Exists.x', 'Still.Exists.y']].mean(axis=1)\n",
    "df['Sarcasm'] = df[['Sarcasm.x', 'Sarcasm.y']].mean(axis=1)\n",
    "df['Disagree.With'] = df[['Disagree.With.x', 'Disagree.With.y']].mean(axis=1)\n",
    "df['Sentiment.Rating'] = df[['Sentiment.Rating.x', 'Sentiment.Rating.y']].mean(axis=1)\n",
    "df['Is.About.the.Holocaust'] = df[['Is.About.the.Holocaust.x', 'Is.About.the.Holocaust.y']].mean(axis=1)\n",
    "df['IHRA.Section'] = df[['IHRA.Section.x', 'IHRA.Section.y']].mean(axis=1)\n",
    "# df['Antisemitism.Rating'] = df[['Antisemitism.Rating.x', 'Antisemitism.Rating.y']].mean(axis=1)\n",
    "df['Calling.Out'] = df[['Calling.Out.x', 'Calling.Out.y']].mean(axis=1)\n",
    "\n",
    "# drop the unwanted columns\n",
    "df.drop(['Still.Exists.x', 'Still.Exists.y','Sarcasm.x', 'Sarcasm.y','Disagree.With.x', 'Disagree.With.y','Sentiment.Rating.x', 'Sentiment.Rating.y','Is.About.the.Holocaust.x', 'Is.About.the.Holocaust.y'],inplace=True,axis=1)\n",
    "# df.drop(['IHRA.Section.x', 'IHRA.Section.y','Antisemitism.Rating.x', 'Antisemitism.Rating.y','Calling.Out.x', 'Calling.Out.y'],inplace=True,axis=1)\n",
    "df.drop(['IHRA.Section.x', 'IHRA.Section.y','Calling.Out.x', 'Calling.Out.y'],inplace=True,axis=1)\n",
    "\n",
    "#train_dataset_filtered.columns\n",
    "#train_dataset_filtered.to_csv(\"train_dataset_filtered.csv\", index=False)\n",
    "\n",
    "\n",
    "train_dataset_filtered=df\n",
    "train_two_cols=train_dataset_filtered.loc[:,['full_text','Target']]\n",
    "#smaller_train_dataset=pd.concat([X_train,y_train],axis=1)\n",
    "\n",
    "results= classifier(train_two_cols, pd.DataFrame(train_two_cols['full_text']))\n",
    "results=pd.DataFrame(results,columns=['probabilities_of_1'])\n",
    "\n",
    "fina_train=pd.concat([train_dataset_filtered,results],axis=1)\n",
    "\n",
    "#Need to remove this \n",
    "#fina_train=fina_train.loc[:,['key','Target']]\n",
    "\n",
    "#One hot encoding\n",
    "key_df = pd.get_dummies(fina_train['key'], prefix='key_')\n",
    "fina_train = pd.merge(\n",
    "    left=fina_train,\n",
    "    right=key_df,\n",
    "    left_index=True,\n",
    "    right_index=True,\n",
    "    )\n",
    "fina_train.drop(['full_text','key'],axis=1,inplace=True)\n",
    "#fina_train.drop(['probabilities_of_1','full_text','Additional.Comments.x','Additional.Comments.y','sample_name','key','create_date'],axis=1,inplace=True)\n",
    "#fina_train.drop(['key'],axis=1,inplace=True)\n",
    "\n",
    "\n",
    "#fina_train=fina_train.loc[:,['key','Target']]\n",
    "\n",
    "fina_train['RT_TF']=fina_train['RT_TF'].astype(int)\n",
    "\n",
    "#fina_train.to_csv(\"fina_train.csv\",index=False)\n",
    "\n",
    "#Splitiing data\n",
    "y=fina_train.loc[:,['Target']]\n",
    "X=fina_train.drop(['Target'],axis=1)\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.2, random_state = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "5814100f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-23-8f2763381873>:4: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  classifier2.fit(X_train, y_train)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "RandomForestClassifier(criterion='entropy', n_estimators=500, random_state=0)"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#RandomForest\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "classifier2 = RandomForestClassifier(n_estimators = 500, criterion = 'entropy', random_state = 0)\n",
    "classifier2.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "50cc6b7b",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = classifier2.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "21e75a95",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.0"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Evaluation of model\n",
    "from sklearn.metrics import confusion_matrix, accuracy_score\n",
    "accuracy_score(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "5b278f55",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'              precision    recall  f1-score   support\\n\\n           0       1.00      1.00      1.00       488\\n           1       1.00      1.00      1.00       156\\n\\n    accuracy                           1.00       644\\n   macro avg       1.00      1.00      1.00       644\\nweighted avg       1.00      1.00      1.00       644\\n'"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "classification_report(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "31987c10",
   "metadata": {},
   "outputs": [],
   "source": [
    "#------------------------------------------------------Test data----------------------------------------\n",
    "os.chdir(r\"C:\\Key files- GNA\\Indiana University\\Hackathon\\Data Science- March\")\n",
    "test_dataset=pd.read_csv(\"test_dataset_latest.csv\")\n",
    "#test_dataset_filtered=test_dataset\n",
    "\n",
    "test_dataset_filtered=test_dataset.drop(['Additional.Comments.x','Additional.Comments.y','sample_name','create_date','Unnamed: 0', 'Unnamed: 0.1','ID', 'user','userID','Sample.ID.x','Sample.ID.y','In.English.x', 'In.English.y','User.x', 'User.y'],axis=1)\n",
    "\n",
    "#Cleaning\n",
    "df=test_dataset_filtered\n",
    "# merge two columns that are same just few values are in one column and rest in other\n",
    "df['Is.About.the.Holocaust.x'] = df['Is.About.the.Holocaust.x'].fillna(df['Is.About.The.Holocaust.x'])\n",
    "df['Is.About.the.Holocaust.y'] = df['Is.About.the.Holocaust.y'].fillna(df['Is.About.The.Holocaust.y'])\n",
    "# drop the unwanted columns \n",
    "df.drop(['Is.About.The.Holocaust.x','Is.About.The.Holocaust.y'],inplace=True,axis=1)\n",
    "\n",
    "# Average out to columns that have same meaning except are filled by different experts\n",
    "# Approach used: average out the values \n",
    "df['Still.Exists'] = df[['Still.Exists.x', 'Still.Exists.y']].mean(axis=1)\n",
    "df['Sarcasm'] = df[['Sarcasm.x', 'Sarcasm.y']].mean(axis=1)\n",
    "df['Disagree.With'] = df[['Disagree.With.x', 'Disagree.With.y']].mean(axis=1)\n",
    "df['Sentiment.Rating'] = df[['Sentiment.Rating.x', 'Sentiment.Rating.y']].mean(axis=1)\n",
    "df['Is.About.the.Holocaust'] = df[['Is.About.the.Holocaust.x', 'Is.About.the.Holocaust.y']].mean(axis=1)\n",
    "df['IHRA.Section'] = df[['IHRA.Section.x', 'IHRA.Section.y']].mean(axis=1)\n",
    "# df['Antisemitism.Rating'] = df[['Antisemitism.Rating.x', 'Antisemitism.Rating.y']].mean(axis=1)\n",
    "df['Calling.Out'] = df[['Calling.Out.x', 'Calling.Out.y']].mean(axis=1)\n",
    "\n",
    "# drop the unwanted columns\n",
    "df.drop(['Still.Exists.x', 'Still.Exists.y','Sarcasm.x', 'Sarcasm.y','Disagree.With.x', 'Disagree.With.y','Sentiment.Rating.x', 'Sentiment.Rating.y','Is.About.the.Holocaust.x', 'Is.About.the.Holocaust.y'],inplace=True,axis=1)\n",
    "# df.drop(['IHRA.Section.x', 'IHRA.Section.y','Antisemitism.Rating.x', 'Antisemitism.Rating.y','Calling.Out.x', 'Calling.Out.y'],inplace=True,axis=1)\n",
    "df.drop(['IHRA.Section.x', 'IHRA.Section.y','Calling.Out.x', 'Calling.Out.y'],inplace=True,axis=1)\n",
    "\n",
    "#test_dataset_filtered.columns\n",
    "#test_dataset_filtered.to_csv(\"test_dataset_filtered.csv\", index=False)\n",
    "\n",
    "test_two_cols=test_dataset_filtered.loc[:,['full_text']]\n",
    "#smaller_test_dataset=pd.concat([X_test,y_test],axis=1)\n",
    "\n",
    "results= classifier(train_two_cols, pd.DataFrame(test_two_cols['full_text']))\n",
    "results=pd.DataFrame(results,columns=['probabilities_of_1'])\n",
    "\n",
    "fina_test=pd.concat([test_dataset_filtered,results],axis=1)\n",
    "\n",
    "#One hot encoding\n",
    "key_df = pd.get_dummies(fina_test['key'], prefix='key_')\n",
    "fina_test = pd.merge(\n",
    "    left=fina_test,\n",
    "    right=key_df,\n",
    "    left_index=True,\n",
    "    right_index=True,\n",
    ")\n",
    "#fina_test.drop(['full_text','Additional.Comments.x','Additional.Comments.y','sample_name','key','create_date'],axis=1,inplace=True)\n",
    "\n",
    "fina_test.drop(['full_text','key'],axis=1,inplace=True)\n",
    "\n",
    "fina_test['RT_TF']=fina_test['RT_TF'].astype(int)\n",
    "\n",
    "# RF\n",
    "y_pred_final_test = classifier2.predict(fina_test)\n",
    "y_pred_final_test =pd.DataFrame(y_pred_final_test,columns=['Target'])\n",
    "y_pred_final_test.to_csv(\"final_submission_10_lr.csv\",index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "825b58fa",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
